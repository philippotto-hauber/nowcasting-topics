rm(list = ls())
setwd("C:/Users/Philipp/Documents/GitHub/nowcasting-topics/data")
#_____________________________________________________#
#_This script ...
#_____________________________________________________#

# PACKAGES ----
library(lubridate)
library(dplyr)
library(tidyr)
library(bundesbank)
library(tibble)

# FUNCTIONS ----
#_____________________________________________________#
#_f_interpolate (currently not required),
#_ roll_mean 
#_ bw_filter
#_ f_outl
#_____________________________________________________#

f_interpolate <- function(x)
# replace NA in x with linear interpolation
{
  for (t in seq(1, length(x)))
  {
    if (is.na(x[t]))
    {
      ind_nextobs <- 0
      t_NA = T
      while (t_NA == T)
      {
        
        if (is.na(x[t+ind_nextobs]))
          ind_nextobs <- ind_nextobs + 1
        else
          t_NA = F
        
      }
      x[t] <- 0.5 * (x[t-1] + x[t+ind_nextobs])
    }
  }
  return(x)
}

rollmean <- function(x, k){
  xroll <- array(NA, c(length(x)))
  for (t in seq(k, length(x)))
    xroll[t] <- mean(x[(t-k+1):t], na.rm = TRUE)
  
  return(xroll)
}

bw_filter <- function(y, bw)
{
  # compute un-normalized weights
  j <- seq(-bw, bw, 1) 
  omeg = (1 - (j/bw) ^ 2) ^ 2  
  
  # check for NA's in y
  n_NA <- sum(is.na(y)) 
  y_noNA <- y[(n_NA + 1) : length(y)]
  Nt <- length(y_noNA)
  
  # loop over t
  tau <- mat.or.vec(length(y_noNA), 1)
  for (t in 1 : length(y_noNA)) {
    # case distinction
    if (t <= bw) {
      
      indY <- c(1 : (2 * bw - (bw - t)))
      indOmeg <- c((bw - t + 1):(2 * bw)) 
      kap <- 1 / ( sum(omeg[indOmeg]))
      tau[ t ] <- kap * omeg[indOmeg] %*% y_noNA[indY] 
      
    } else if (t > (Nt - bw)) {
      
      indY <- c((t - bw) : Nt)
      indOmeg <- c(1 : (bw + 1 + (Nt - t)))
      kap <- 1 / ( sum( omeg[indOmeg] ) )
      tau[t] <- kap * omeg[indOmeg] %*% y_noNA[indY] 
      
    } else {
      
      indY <- seq(t - bw, t + bw, 1)
      indOmeg <- c( 1 : (2 * bw + 1))
      kap <- 1 / (sum(omeg[indOmeg]))
      tau[t] <- kap * omeg[indOmeg] %*% y_noNA[indY]  
    }
  }
  return(c(rep(NA, times = n_NA), tau))
}

f_outl <- function(y, aalpha)
{
  return(abs((y - median(y, na.rm = T))) > aalpha * IQR(y, na.rm = T))
}

# SET-UP ----
#_____________________________________________________#
#_sample_start,
#_specify vintage, 
#_forecast horizon,
#_number of topics to select
#_window of moving average
#_band width
#_aalpha
#_(these parameters will be function input at a later point)
#_____________________________________________________#

sample_start <- c("1995-01-01")
vintage <- c("2010-01-30") # requires backcast!
date_h <- c("2010-09-30") # 2010Q2
Ntopics <- 10 # select Ntopics topics that have the highest correlation with quarterly GDP growth
K = 60 # window of moving average
bw = 1200 # bandwidth for biweight filter
aalpha <- 10 # number of IQR between median to determine outlier
corr_select <- 0.25 # include topics with an absolute correlation larger than corr_select

# LOAD TOPICS ----
#_____________________________________________________#
#_select sample,
#_extend to 7-day week,
#_linearly interpolate to fill-in NA (commented out because not necessary)
#_____________________________________________________#

df_raw <- read.csv("./topics/daily_topics_2.csv")

# add date and quarter variable
df_raw %>%
  mutate(date = make_date(year = df_raw$year, 
                          month = df_raw$month, 
                          day = df_raw$day),
         quarter = ceiling(month / 3)) %>% 
  filter(date <= vintage) %>%
  select(date, year, quarter, month, day, everything()) -> df_topics 

# get rid of raw df
rm(df_raw)

# extend series with NA to 7-day week 
dates_tmp <- data.frame(date = seq(min(df_topics$date), 
                           max(df_topics$date), 
                           by = "days")
                )

dates_tmp %>% 
  mutate(year = year(date),
         month = month(date),
         quarter = ceiling(month / 3),
         day = day(date)) %>%
  merge(df_topics, by = c("date", "year", "quarter", "month", "day"), all.x = T) -> df_topics

# get rid of dates_tmp
rm(dates_tmp)

# col indices corresponding to topics
ind_topics <- which(grepl("T", names(df_topics)))

# adjust sample (leaving K additional rows at start which will be removed after smoothing)
df_topics %>% filter(date >= as.Date(sample_start) - days(K)) -> df_topics

# linear interpolate topics to fill-in missings, storing pattern of NA => commented out because moving average should take care of missings
# ind_NA <- c()
# for (n in ind_topics)
# {
#   x <- df_topics[, n]
#   ind_NA <- cbind(ind_NA, is.na(x))
#   x <- f_interpolate(x)
#   df_topics[, n] <- x
# }
# 
# colnames(ind_NA) <- names(df_topics)[grepl("T", names(df_topics))]

# TRANSFORM TOPICS ---- 
#_____________________________________________________#
#_rm outlier,
#_moving average,
#_detrend using biweight filter
#_reimpose NA pattern
#_adjust sample
#_____________________________________________________#

# remove outlier
ind_outl <- apply(df_topics[, ind_topics], c(2), f_outl, aalpha = aalpha)
dat <- df_topics[, ind_topics]
dat[ind_outl] <- NA

# store pattern of missings
ind_NA <- is.na(dat)
colnames(ind_NA) <- names(df_topics)[grepl("T", names(df_topics))]

# moving average
dat_ma <- apply(dat, c(2), rollmean, k = K)

# detrend with biweight filter
dat_bw <- apply(dat_ma, c(2), bw_filter, bw = bw)
dat_detrend <- dat_ma - dat_bw # de-trended topics

# reimpose NA pattern
dat_detrend_NA <- dat_detrend
dat_detrend_NA[ind_NA] <- NA

# store in df_topics_trafo
df_topics_trafo <- df_topics
df_topics_trafo[ind_topics] <- dat_detrend_NA

# rm first K rows
df_topics_trafo <- df_topics_trafo[seq(K+1, nrow(df_topics_trafo)), ]

plot(df_topics$date, df_topics[, 7], 
     type = "l", col = "blue", 
     ylim = c(-0.02, 0.12), 
     main = "Topic T1", sub = "raw and detrended series",
     ylab = "",
     xlab = "")
lines(df_topics_trafo$date, df_topics_trafo[, 7], type = "l", col = "red")

# DOWNLOAD GDP DATA ----

# load from file
load("vintages_gdp.Rda")

# select vintage
dates_vintages <- as.Date(names(df_gdp))
ind_vintage <- sum(dates_vintages <= vintage)
df_gdp <- df_gdp[, ind_vintage, drop = F]

# convert dates to column
df_gdp %>% 
  select(tail(names(.), 1)) %>%
  rownames_to_column(var = "date") %>%
  mutate(year = as.numeric(substr(date, 1, 4)), 
         month = as.numeric(substr(date, 6, 7))+2,  
         quarter = ceiling(month/3),
         date_tmp = make_date(year = ifelse(month+1>12,year+1, year), month = ifelse(month+1>12,1,month+1), day = 1),
         date = date_tmp - days(1),
         day = day(date)# middle of the quarter, e.g. 15.2. for Q1
        )-> df_gdp

# adjust name of series
names(df_gdp)[2] <- "gdp"

# calculate annualized quarterly growth rate
df_gdp$d_gdp <- c(NA, 400 * diff(log(df_gdp$gdp)))

# select and reorder columns
df_gdp %>% select(date, year, quarter, month, day, d_gdp) -> df_gdp

# convert to "daily" frequency
dates_tmp <- data.frame(date = seq(min(df_topics_trafo$date), 
                                   max(df_topics_trafo$date), 
                                   by = "days")
                        )

dates_tmp %>% 
  mutate(year = year(date),
         month = month(date),
         quarter = ceiling(month / 3),
         day = day(date)) %>%
  merge(df_gdp, by = c("date", "year", "quarter", "month", "day"), all.x = T) -> df_gdp

# get rid of dates_tmp
rm(dates_tmp)

# APPEND ROWS FOR FORECASTS ----

dates_tmp <- data.frame(date = seq(max(df_gdp$date), 
                                   as.Date(date_h), 
                                   by = "days")
                        )

dates_tmp %>% 
  mutate(year = year(date),
         month = month(date),
         quarter = ceiling(month / 3),
         day = day(date)) %>%
  merge(df_gdp, by = c("date", "year", "quarter", "month", "day"), all = T) -> df_gdp

# CREATE Xi_q INDICATOR ----

# create Xi_q indicators that equals 0 at start of period and 1 elsewhere
df_gdp %>% 
  mutate(Xi_qd = ifelse(month %in% c(seq(1, 10, by = 3)) & day == 1, 0, 1)) -> df_gdp

df_gdp$Xi_qd[1] <- 0 # first obs is also "start" of quarter

# WEIGHTS FOR FLOW VARIABLE ----

# days per quarter and average number of days per quarter over the entire sample
df_gdp %>% 
  select(year, quarter, day) %>% 
  filter(!(year == 1994 & quarter == 1)) %>%
  group_by(year, quarter) %>% 
  summarise(n_days_q = n()) %>% 
  ungroup() -> df_n_days_q

df_n_days_q$n_days_avg_q = floor(mean(df_n_days_q$n_days_q))

# loop over quarters to construct W_q_c and W_q_p
years <- seq(year(df_gdp$date[1]), year(df_gdp$date[nrow(df_gdp)])) 
quarters <- seq(1, 4) 
t_prev <- 0
t <- 0
k <- df_n_days_q$n_days_avg_q[1]
df_W_qd <- data.frame()
for (y in years)
{
  for (q in quarters)
  {
    t_prev <- t
    k_t <- df_n_days_q[df_n_days_q$year == y & df_n_days_q$quarter == q, "n_days_q", drop = T]
    if (length(k_t) == 0) # quarter not in sample!
      next
    else
    {
          t <- t + k_t
          s <- seq(t_prev + 1, t)
          #W_qd_c = k * (t + 1 - s) / k_t # see Banbura et al. (2011, p. 30, eqn 10)
          W_qd_c = (t + 1 - s) / k_t # quarterly GDP level  is the average of daily GDP in the respective quarter
          df_W_qd <- rbind(df_W_qd, data.frame(year = y,
                                               quarter = q,
                                               day = seq(1, k_t),
                                               W_qd_c = W_qd_c,
                                               W_qd_p = c(0, rev(W_qd_c[2:length(W_qd_c)]))
                                              )
                          )

    }
  }
}

# cbind to df
df_gdp <- cbind(df_gdp, select(df_W_qd, W_qd_c, W_qd_p))

# PRE-SELECT TOPICS ----

# convert transformed topics to quarterly frequency
df_topics_trafo %>% 
  pivot_longer(cols = -c(date, year, quarter, month, day), 
               names_to = "topic", 
               values_to = "vals") %>%
  group_by(topic, year, quarter) %>%
  summarise(avg_vals = mean(vals, na.rm = T)) %>%
  pivot_wider(id_cols = c(topic, year, quarter), 
              names_from = topic, 
              values_from = avg_vals) -> df_topics_trafo_Q

# merge with quarterly GDP
df_gdp %>%
  filter(!is.na(d_gdp)) %>% 
  select(year, quarter, d_gdp) %>%
  merge(df_topics_trafo_Q, by = c("year", "quarter")) -> df_corr

# calculate correlation between GDP and topics
cor_topics_gdp <- cor(as.matrix(df_corr[, -c(1:2)]))
cor_topics_gdp <- cor_topics_gdp[1, 2:ncol(cor_topics_gdp)] # first row contains correlations of topics with GDP growth

# select those with a correlation of over corr_select in absolute terms
list_topics_select <- names(cor_topics_gdp)[abs(cor_topics_gdp) > corr_select]

df_topics_trafo %>%
  pivot_longer(cols = -c(date, year, quarter, month, day), 
               names_to = "topic", 
               values_to = "vals") %>%
  filter(topic %in% list_topics_select) %>%
  pivot_wider(id_cols = c(topic, date, year, quarter, month, day), 
              names_from = topic, 
              values_from = vals) -> df_topics_trafo

# EXPORT TO CSV ----
#_____________________________________________________#
#_indices for back-, now- and forecasts
#_merge datasets
#_add flag indicating estimation sample 1:Nt
#_change var names
#_____________________________________________________#

# indices for back-, now- and forecasts

df_gdp %>% 
  group_by(year, quarter) %>%
  filter(date == max(date),
         is.na(d_gdp)) %>%
  ungroup() %>%
  select(date) -> dates_fore

diff_q <- floor(as.numeric(dates_fore[, 1, drop = T] - as.Date(vintage)) / 90)

df_ind <- data.frame()
counter_fore <- 1
for (i in seq(1, nrow(dates_fore)))
{
    if (diff_q[i] == -1)
    {
        name <- "ind_backcast"
    } else if (diff_q[i] == 0)
    {
        name <- "ind_nowcast"
    } else {
      name <- paste0("ind_forecast", counter_fore, "Q")
      counter_fore <- counter_fore + 1
    }
    vals <- mat.or.vec(nrow(df_gdp), 1)
    vals[df_gdp$date == dates_fore[i, , drop = T]] <- 1
    
    df_ind <- rbind(df_ind, data.frame(name = name, vals = vals, date = df_gdp$date))
}

pivot_wider(df_ind, names_from = name, values_from = vals) -> df_ind_wide

df_gdp <- merge(df_gdp, df_ind_wide, by = "date")

# merge data sets
df_data <- merge(df_topics_trafo, df_gdp, by = c("date", "year", "quarter", "month", "day"), all = T)

# change var names
ind_q <- grepl("d_gdp", names(df_data))
Nq <- sum(ind_q)
names(df_data)[ind_q] <- paste0("y_q_", seq(1, Nq))

ind_d <- grepl("T.", names(df_data))
Nd <- sum(ind_d)
names(df_data)[ind_d] <- paste0("y_d_", seq(1, Nd))

# add flag for estimation sample
df_data$ind_sample <- ifelse(df_data$date <= vintage, 1, 0)

# export to csv
write.csv(df_data, file = paste0("vint_", year(vintage), "_", month(vintage), "_", day(vintage), ".csv"),
          row.names = F,
          quote = F,
          na = "NaN")
